{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import MultiPoint\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"300\" viewBox=\"502695.32498000126 5025668.23048 19612.62773999787 17535.962539998814\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,10068872.4235)\"><path fill-rule=\"evenodd\" fill=\"#ff3333\" stroke=\"#555555\" stroke-width=\"130.75085159998582\" opacity=\"0.6\" d=\"M 503421.7186000012,5034704.262700001 L 504510.9365000006,5038381.483499999 L 504510.93650000053,5038381.483499999 L 504510.9365000006,5038381.483499999 L 507289.5577000005,5041542.987299998 L 507289.55770000006,5041542.987299998 L 507524.5321000007,5041611.723899999 L 507524.5321000006,5041611.723899999 L 513086.28830000025,5042477.799399999 L 514048.4417000001,5042424.5095 L 514062.7408999994,5042421.386899999 L 516803.2664999997,5041766.145899999 L 516803.2664999996,5041766.145899999 L 520226.2008999993,5040688.596899998 L 520226.20089999924,5040688.596899998 L 521003.7098999998,5040391.7188 L 521003.7098999997,5040391.7188 L 521003.7098999993,5040391.7188 L 521006.75759999926,5040387.4295 L 521006.7575999992,5040387.429500001 L 521578.7782999994,5039064.515699999 L 521578.7782999995,5039064.5156999985 L 521578.7782999994,5039064.5156999985 L 521581.5590999992,5039032.356899999 L 521580.32649999944,5038985.827099999 L 521267.96549999894,5035296.005100001 L 520870.54029999947,5031587.520099999 L 520870.5402999995,5031587.520099999 L 520714.7408999987,5031182.2118999995 L 520714.74089999875,5031182.2118999995 L 520710.383299999,5031173.9265 L 520708.51209999906,5031170.368899999 L 520700.85389999964,5031155.8094999995 L 520700.8538999997,5031155.8095 L 519684.4855999995,5029946.3273 L 518923.2294999996,5029066.999100001 L 518923.22949999967,5029066.999100001 L 518923.2294999997,5029066.999100001 L 516144.8574999993,5026671.9247 L 516144.85749999963,5026671.9247 L 516126.6310999996,5026665.945100001 L 516126.6310999997,5026665.945100001 L 514285.5617000008,5026394.624100001 L 504699.111100001,5031419.4916 L 503448.00850000116,5032673.764300001 L 503448.0085000012,5032673.764300001 L 503446.187500001,5032675.7373 L 503421.71860000124,5034704.262700001 L 503421.7186000012,5034704.262700001 z M 504510.9365000006,5038381.483499999 L 504510.93650000077,5038381.4835 L 504510.9365000007,5038381.4835 L 504510.9365000006,5038381.483499999 z\" /></g></svg>",
      "text/plain": [
       "<POLYGON ((503421.719 5034704.263, 504510.937 5038381.483, 504510.937 503838...>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milan_buildings_polys = gpd.read_file(\"data/footprints/Milano.shp\").geometry\n",
    "milan_buildings_points = [building.convex_hull.exterior.coords for building in milan_buildings_polys]\n",
    "outer_milan = MultiPoint(list(itertools.chain.from_iterable(milan_buildings_points))).convex_hull.buffer(-1e-9)\n",
    "gpd.GeoDataFrame(pd.DataFrame([{\"id\": \"0\"}]), geometry=[outer_milan],crs=\"EPSG:7791\").to_file(\"data/coverage.shp\")\n",
    "outer_milan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input_gdf = gpd.read_file(\"data/coverage.shp\").to_crs(\"EPSG:4326\")\n",
    "sample_coverage = list(sample_input_gdf[\"geometry\"])[0]\n",
    "CONTRACT_NUMBER = 145\n",
    "\n",
    "# Specify intersection\n",
    "contract_data = gpd.read_file(f\"metadata/contract_{CONTRACT_NUMBER}/metadata_contract_{CONTRACT_NUMBER}.shp\")\n",
    "\n",
    "def get_intersection_tiles(input_polygon, lidar_coverage):\n",
    "    intersection_array = lidar_coverage.geometry.map(lambda x: x.intersects(input_polygon))\n",
    "    return lidar_coverage[intersection_array][[\"id\", \"region\"]]\n",
    "\n",
    "intersection = get_intersection_tiles(sample_coverage, contract_data)\n",
    "\n",
    "# Copy files from HDD\n",
    "source_path_prefix = \"/Volumes/Seagate Expansion Drive/just_points\"\n",
    "destination_path_prefix = \"data/lidar_points/raw\"\n",
    "\n",
    "def get_point_file_path(region, contract, filename):\n",
    "    return os.path.join(source_path_prefix, region, f\"Contratto_{contract}\", \"PUNTI\", f\"{filename}.zip\")\n",
    "\n",
    "files_to_copy = [get_point_file_path(row[\"region\"], str(CONTRACT_NUMBER), row[\"id\"]) for _, row in intersection.iterrows()]\n",
    "for filepath in files_to_copy:\n",
    "    dst = os.path.join(destination_path_prefix, filepath.split(\"/\")[-1])\n",
    "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "    shutil.copy(filepath, dst)\n",
    "\n",
    "# Extract Zips\n",
    "for filename in os.listdir(destination_path_prefix):  \n",
    "    filepath = os.path.join(destination_path_prefix, filename)\n",
    "    if zipfile.is_zipfile(filepath):\n",
    "        with zipfile.ZipFile(filepath) as item:\n",
    "           item.extractall(destination_path_prefix) \n",
    "\n",
    "# Remove Zips\n",
    "for filename in os.listdir(destination_path_prefix): \n",
    "    if filename.endswith(\"zip\"):\n",
    "        os.remove(os.path.join(destination_path_prefix, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprints_raw = gpd.read_file(\"data/footprints/Milano.shp\").to_crs(\"EPSG:4326\")\n",
    "coverage_140 = gpd.read_file(\"metadata/contract_140/metadata_contract_140.shp\")\n",
    "coverage_145 = gpd.read_file(\"metadata/contract_145/metadata_contract_145.shp\")\n",
    "\n",
    "def prepare_points(points_filename):\n",
    "    points = pd.read_csv(f\"data/lidar_points/{points_filename}.xyz\", names=[\"long\",\"lat\",\"elevation\",\"_1\",\"_2\"], delim_whitespace=True)\n",
    "    points = points[[\"long\",\"lat\", \"elevation\"]].rename(columns={'lat': 'x', 'long': 'y', 'elevation': 'z'})\n",
    "    points.insert(0, 'id', range(0, len(points)))\n",
    "    path = f\"data/tmp/points_{points_filename}.csv\"\n",
    "    points.to_csv(path, index=False)\n",
    "    return path\n",
    "\n",
    "def prepare_footprints(points_filename):\n",
    "    coverage_tiles_140 = list(coverage_140[coverage_140[\"id\"] == points_filename].geometry)\n",
    "    coverage_tiles_145 = list(coverage_145[coverage_145[\"id\"] == points_filename].geometry)\n",
    "    \n",
    "    coverage_tile = coverage_tiles_140[0] if coverage_tiles_140 else coverage_tiles_145[0]\n",
    "    footprints_intersection = footprints_raw.geometry.map(lambda x: x.intersects(coverage_tile))\n",
    "    footprints = footprints_raw[footprints_intersection][[\"OBJECTID\", \"edifc_stat\", \"edifc_ty\", \"edifc_uso\", \"geometry\"]]\\\n",
    "        .rename(columns={'OBJECTID': 'id'})\n",
    "    path = f\"data/tmp/footprints_{points_filename}.csv\"\n",
    "    footprints.to_csv(path, index=False)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D45440915_0101_Punti\n",
      "D45500925_0101_Punti\n",
      "D45470914_0101_Punti\n",
      "D45420917_0101_Punti\n",
      "D45490915_0101_Punti\n",
      "D45410916_0101_Punti\n",
      "e1140682f02b484d7bd72c808b10a469dd2e996eb8752f798c25c1537ca8969a\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "COPY 1538968\n",
      "UPDATE 1538968\n",
      "COPY 102\n",
      "UPDATE 102\n",
      "UPDATE 102\n",
      "COPY 102\n",
      "skynet\n",
      "skynet\n",
      "D45450926_0101_Punti\n",
      "74404e733ce344f6a43d86f8ae35cfd37664b29c7c690c74353d75fe26d94f14\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "COPY 1480270\n",
      "UPDATE 1480270\n",
      "COPY 31\n",
      "UPDATE 31\n",
      "UPDATE 31\n",
      "COPY 31\n",
      "skynet\n",
      "skynet\n",
      "D45510916_0101_Punti\n",
      "2516909a35c451503b133b7d0f9713a1e440f56e3f23f539bf38d60374e81cc6\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "COPY 1769504\n",
      "UPDATE 1769504\n",
      "COPY 338\n",
      "UPDATE 338\n",
      "UPDATE 338\n",
      "COPY 338\n",
      "skynet\n",
      "skynet\n",
      "D45520917_0101_Punti\n",
      "960c448751d5d49ae7bd974b751a8d95c0df6a9fa08edfd982f084f6bf1897db\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "COPY 3453652\n",
      "UPDATE 3453652\n",
      "COPY 496\n",
      "UPDATE 496\n",
      "UPDATE 496\n",
      "COPY 496\n",
      "skynet\n",
      "skynet\n",
      "D45460927_0101_Punti\n",
      "10a841a58c87dbb066a75a2ef9394946c82fef38d37b1a0829a4e1e18a6a54e7\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "COPY 552643\n",
      "UPDATE 552643\n",
      "COPY 0\n",
      "UPDATE 0\n",
      "UPDATE 0\n",
      "COPY 0\n",
      "skynet\n",
      "skynet\n",
      "D45480926_0101_Punti\n",
      "9e901881bb6eb635e1fa77786f99fa9aff0b40827311f1db94c84f5b11f26d63\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "COPY 1589371\n",
      "UPDATE 1589371\n",
      "COPY 5\n",
      "UPDATE 5\n",
      "UPDATE 5\n",
      "COPY 5\n",
      "skynet\n",
      "skynet\n",
      "D45430924_0101_Punti\n",
      "8f0bfc8a953bb8d1070b799f7d854c21d1667b2419c030739fd2373841f27c30\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "COPY 1574915\n",
      "UPDATE 1574915\n",
      "COPY 315\n",
      "UPDATE 315\n",
      "UPDATE 315\n",
      "COPY 315\n",
      "skynet\n",
      "skynet\n",
      "D45490908_0101_Punti\n",
      "c9798851817c95844ca8fbca100284ee1e91e24b283327581bed28dc5bc973cb\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "COPY 1718729\n",
      "UPDATE 1718729\n",
      "COPY 45\n",
      "UPDATE 45\n",
      "UPDATE 45\n",
      "COPY 45\n",
      "skynet\n",
      "skynet\n",
      "D45470909_0101_Punti\n",
      "39f656c7ed88124e5901d8c0de9e2e5f4a6af1e529040ecc2e39e6d22d971338\n",
      "CREATE TABLE\n",
      "CREATE TABLE\n",
      "COPY 1524701\n",
      "UPDATE 1524701\n",
      "COPY 74\n",
      "UPDATE 74\n",
      "UPDATE 74\n",
      "COPY 74\n",
      "skynet\n",
      "skynet\n",
      "D45440908_0101_Punti\n",
      "b82800f846017ccc1b8e1cbef8609392a8c1f55e4b0b39725db8c6bfe8afe758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "psql:/tmp/preprocessing.sql:12: ERROR:  type \"geometry\" does not exist\n",
      "LINE 7:     geometry geometry(Point, 4326),\n",
      "                     ^\n",
      "psql:/tmp/preprocessing.sql:24: ERROR:  type \"geometry\" does not exist\n",
      "LINE 8:     geometry geometry(MultiPolygon,4326),\n",
      "                     ^\n",
      "psql:/tmp/preprocessing.sql:29: ERROR:  relation \"points\" does not exist\n",
      "psql:/tmp/preprocessing.sql:31: ERROR:  relation \"points\" does not exist\n",
      "LINE 1: update points set geometry = ST_MakePoint(x, y), final_geome...\n",
      "               ^\n",
      "psql:/tmp/preprocessing.sql:36: ERROR:  relation \"footprints\" does not exist\n",
      "psql:/tmp/preprocessing.sql:38: ERROR:  relation \"footprints\" does not exist\n",
      "LINE 1: update footprints set geometry = ST_Multi(ST_GeomFromText(ge...\n",
      "               ^\n",
      "psql:/tmp/preprocessing.sql:39: ERROR:  relation \"footprints\" does not exist\n",
      "LINE 1: update footprints set buffered_geometry = ST_Buffer(geometry...\n",
      "               ^\n",
      "psql:/tmp/preprocessing.sql:103: ERROR:  relation \"footprints\" does not exist\n",
      "LINE 56:    FROM footprints f\n",
      "                 ^\n",
      "Error: No such container:path: skynet:/tmp/output_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skynet\n",
      "skynet\n",
      "D45410911_0101_Punti\n",
      "e443ba27e2f9cb525e64082cf2855c71be9bbe9042078ca13c15a9e24778f632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error response from daemon: Container e443ba27e2f9cb525e64082cf2855c71be9bbe9042078ca13c15a9e24778f632 is not running\n",
      "Error: No such container:path: skynet:/tmp/output_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skynet\n",
      "skynet\n",
      "D45490907_0101_Punti\n"
     ]
    }
   ],
   "source": [
    "points_files = [f for f in os.listdir(\"data/lidar_points/\") if f.endswith(\"xyz\")]\n",
    "for filename in points_files: #['D45420917_0101_Punti.xyz']\n",
    "    points_filename = filename[:-4]\n",
    "    print(points_filename)\n",
    "    if not f\"{points_filename}.csv\" in os.listdir(\"data/postgis_output/\"):\n",
    "        points_path = prepare_points(points_filename)\n",
    "        footprints_path = prepare_footprints(points_filename)\n",
    "        output_path = f\"data/postgis_output/{points_filename}.csv\"\n",
    "        os.system(f\"./postgis_processing.sh {points_path} {footprints_path} {output_path}\")\n",
    "        os.remove(footprints_path)\n",
    "        os.remove(points_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d506b227a3c59d6de1745325b7f893f27654647f30ac90ae78bcfba722100e86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
